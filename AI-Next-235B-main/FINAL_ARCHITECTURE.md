# Архитектура мировой нейросети (обновленная версия)

## Общая структура

Нейросеть состоит из:
- 2 начальных слоев: Embedding и Positional Encoding
- 12 идентичных суперблоков (каждый с 8 слоями = 96 слоев всего)
- 3 финальных слоя: Final RMSNorm, Output Layer (Unembedding), и Softmax/Sampling
- Всего: ~101 слой с приблизительно 235 миллиардами параметров

## Подробная структура суперблока

Каждый суперблок содержит 8 слоев:
1. RMSNorm
2. Gated DeltaNet (Linear Attention)
3. MoE FFN Layer (High-Capacity) - 256 экспертов, 42 активных на токен
4. RMSNorm
5. Grouped Query Attention (GQA)
6. MoE FFN Layer (High-Capacity) - 256 экспертов, 42 активных на токен
7. RMSNorm
8. Multi-Token Prediction (MTP) Head

## Ключевые компоненты

### Mixture of Experts (MoE)
- 256 экспертов на слой (как и требовалось)
- 42 активных эксперта на токен (как и требовалось)
- 2 специальных токена для классификации по интонации и научной области
- Остальные токены используют 42 активных эксперта

### Специализированный слой управления контекстом
- Разделяет контекст на важный/неважный и срочный/обычный (матрица Эйзенхауэра)
- Использует специализированную нейросеть для анализа
- Включает графический интерфейс для визуализации

### Дополнительные компоненты
- Gated DeltaNet (линейное внимание)
- Grouped Query Attention (GQA)
- RMSNorm (корневая нормализация)
- Multi-Token Prediction Head (предсказание нескольких токенов)

## Параметры модели

- Вокабуляр: 50257 (GPT-2)
- Размер скрытого слоя: 8192
- Количество голов внимания: 64
- Размер FFN: 32768
- Максимальная длина последовательности: 2048
- Количество суперблоков: 12
- Общее количество параметров: ~235 миллиардов

## Обучение на датасете The Pile

- Поддержка распределенного обучения с использованием DeepSpeed
- Поддержка градиентного аккумулятора
- Поддержка FP16 для экономии памяти
- Поддержка Zero-3 для экономии памяти

## Требования к оборудованию

- 8 или более GPU NVIDIA A100 (80GB) или H100
- Не менее 1 ТБ оперативной памяти (рекомендуется 2 ТБ)
- Высокоскоростная сеть между узлами (InfiniBand)
- Не менее 5 ТБ дискового пространства для чекпоинтов и логов
- 100 Гбит/с сеть для распределенного обучения

## Производительность

Модель разработана для достижения уровня производительности, сравнимого с GPT-4o, с возможностью понимания сложных контекстов благодаря инновационному слою управления контекстом по матрице Эйзенхауэра.